# Computational Foundations of Regression: Numerical Stability and Scalability

This project investigates the computational aspects of linear regression with a focus on:

- **Numerical stability** of direct methods  
- **Scalability** of gradient-based optimization (BGD vs. SGD)  
- **Non-linear extension** using polynomial regression  

The notebook includes:

- Implementation of Normal Equations, SVD pseudoinverse, Batch Gradient Descent, and Stochastic Gradient Descent  
- Stability analysis under collinearity  
- Convergence comparison on the Auto MPG dataset  
- Polynomial (degree-2) regression model trained with SGD  

All generated figures are saved in the `outputs/` directory.
